{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Label Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SOMSN_D57gN",
        "colab_type": "text"
      },
      "source": [
        "# Import relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Juj9Iy4pH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.backend as K\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBYcJNBL52OB",
        "colab_type": "text"
      },
      "source": [
        "# Loading Images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fmUb_a9MA1y",
        "colab_type": "code",
        "outputId": "719794d8-0231-45b9-813a-5b30591d1ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train = pd.read_csv('Multi_Label_dataset/train.csv')\n",
        "\n",
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('Multi_Label_dataset/Images/'+train['Id'][i]+'.jpg',target_size=(224,224,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)\n",
        "\n",
        "y = np.array(train.drop(['Id', 'Genre'],axis=1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7254/7254 [00:20<00:00, 359.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42f23R835r_r",
        "colab_type": "text"
      },
      "source": [
        "# Making and compiling the CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hUU28J1Y6LU",
        "colab_type": "code",
        "outputId": "8b4e16bc-11fe-4326-de51-f9feb7f11275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(224,224,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(25, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 220, 220, 16)      1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 110, 110, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 110, 110, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 106, 106, 32)      12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 53, 53, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 53, 53, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 49, 49, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               819328    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                1625      \n",
            "=================================================================\n",
            "Total params: 996,985\n",
            "Trainable params: 996,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtoVZZ5r5pDK",
        "colab_type": "text"
      },
      "source": [
        "# Training for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb41udxiY8fQ",
        "colab_type": "code",
        "outputId": "6d47a723-1e96-478c-94fc-dcf01dcf8699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 5875 samples, validate on 653 samples\n",
            "Epoch 1/10\n",
            "5875/5875 [==============================] - 12s 2ms/sample - loss: 0.3469 - acc: 0.8636 - val_loss: 0.2474 - val_acc: 0.9070\n",
            "Epoch 2/10\n",
            "5875/5875 [==============================] - 6s 948us/sample - loss: 0.2671 - acc: 0.9046 - val_loss: 0.2409 - val_acc: 0.9060\n",
            "Epoch 3/10\n",
            "5875/5875 [==============================] - 6s 946us/sample - loss: 0.2574 - acc: 0.9069 - val_loss: 0.2394 - val_acc: 0.9060\n",
            "Epoch 4/10\n",
            "5875/5875 [==============================] - 6s 954us/sample - loss: 0.2519 - acc: 0.9074 - val_loss: 0.2420 - val_acc: 0.9055\n",
            "Epoch 5/10\n",
            "5875/5875 [==============================] - 6s 948us/sample - loss: 0.2493 - acc: 0.9080 - val_loss: 0.2361 - val_acc: 0.9075\n",
            "Epoch 6/10\n",
            "5875/5875 [==============================] - 6s 939us/sample - loss: 0.2472 - acc: 0.9086 - val_loss: 0.2366 - val_acc: 0.9085\n",
            "Epoch 7/10\n",
            "5875/5875 [==============================] - 6s 938us/sample - loss: 0.2449 - acc: 0.9087 - val_loss: 0.2367 - val_acc: 0.9078\n",
            "Epoch 8/10\n",
            "5875/5875 [==============================] - 5s 936us/sample - loss: 0.2437 - acc: 0.9097 - val_loss: 0.2352 - val_acc: 0.9101\n",
            "Epoch 9/10\n",
            "5875/5875 [==============================] - 6s 943us/sample - loss: 0.2429 - acc: 0.9093 - val_loss: 0.2370 - val_acc: 0.9089\n",
            "Epoch 10/10\n",
            "5875/5875 [==============================] - 6s 940us/sample - loss: 0.2417 - acc: 0.9098 - val_loss: 0.2379 - val_acc: 0.9081\n",
            "726/726 [==============================] - 0s 508us/sample - loss: 0.2386 - acc: 0.9101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23862200790692953, 0.91013765]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REkWRMGl5TdF",
        "colab_type": "text"
      },
      "source": [
        "# Assesing Model performance\n",
        "## As seen by the f1 score and the correspoding lrap and hamming loss it is evident that the high accuracy is the result of of extreme overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNb3Llh8bL1K",
        "colab_type": "code",
        "outputId": "39dc79a6-35c9-40b9-fcdf-37286c6dcbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, label_ranking_average_precision_score, hamming_loss\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "pred = model.predict(X_val)\n",
        "\n",
        "print(\"\\nlabel_ranking_average_precision_score\")\n",
        "print(label_ranking_average_precision_score(np.round(pred), y_val))\n",
        "\n",
        "print(\"\\nhamming_loss\")\n",
        "print(hamming_loss(np.round(pred), y_val))\n",
        "\n",
        "print(\"\\nClasswise f1_score\")\n",
        "f1 = []\n",
        "for i in list(pd.DataFrame(np.round(y_val))):\n",
        "  f1.append([f1_score(pd.DataFrame(np.round(pred))[i], pd.DataFrame(np.round(y_val))[i])])\n",
        "\n",
        "pd.DataFrame(f1).hist()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "label_ranking_average_precision_score\n",
            "0.3232669729453806\n",
            "\n",
            "hamming_loss\n",
            "0.0919448698315467\n",
            "\n",
            "Classwise f1_score\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}