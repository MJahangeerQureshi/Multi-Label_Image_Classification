{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experimentation for improving Multi-Label Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dkjrBJMETd9",
        "colab_type": "text"
      },
      "source": [
        "# Importing the relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aia9fXQ_42Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras as keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, InputLayer\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.backend as K\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d3xXegpEaxC",
        "colab_type": "text"
      },
      "source": [
        "#Loading and normalizing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lGZ73sjUbO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('Multi_Label_dataset/train.csv')\n",
        "\n",
        "diff=[]\n",
        "\n",
        "for i in list(train.drop(['Id', 'Genre'],axis=1)):\n",
        "  d = list(train.drop(['Id', 'Genre'],axis=1)[i].value_counts())\n",
        "  diff.append([i, np.abs(d[0] - d[1])])\n",
        "\n",
        "selected_classes = pd.DataFrame(diff).sort_values(1)\n",
        "\n",
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('Multi_Label_dataset/Images/'+train['Id'][i]+'.jpg',target_size=(224,224,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)\n",
        "y = train.drop(['Id', 'Genre'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO1TG7wQEsLK",
        "colab_type": "text"
      },
      "source": [
        "# Functions for compiling a pretarined model as well a function for classwise data selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeE0mLSABjuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(freeze=True, tpu=True):\n",
        "  model = Sequential()\n",
        "  model.add(VGG16(include_top=False, input_shape=(224,224,3)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  if freeze:\n",
        "    model.layers[0].trainable = False\n",
        "  \n",
        "  if tpu:\n",
        "    model = get_tpu_model(model)\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "  def get_tpu_model(model):\n",
        "    if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "        print('ERROR: Not connected to a TPU runtime')\n",
        "        return model\n",
        "    else:\n",
        "        TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "        print ('TPU address is', tpu_address)\n",
        "\n",
        "        tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "            model,\n",
        "            strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "              tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))\n",
        "        return tpu_model\n",
        "\n",
        "def get_training_data(class_name):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, np.array(y[class_name]), random_state=42, test_size=0.2, stratify=np.array(y[class_name]))\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.2, stratify=y_train)\n",
        "\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64gwarnVE6eG",
        "colab_type": "text"
      },
      "source": [
        "# Training seperate models for each of the classes accounting for class imbalance and ensuring that testing and validation class distributions are similar to the training distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlhQey-kCec-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, label_ranking_average_precision_score, hamming_loss\n",
        "\n",
        "\n",
        "for c in tqdm(list(selected_classes[0])):\n",
        "  X_train, X_val, X_test, y_train, y_val, y_test = get_training_data(c)\n",
        "  model = get_model()\n",
        "  \n",
        "  model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=32)\n",
        "  pred = model.predict(X_val)\n",
        "\n",
        "  print(\"Classwise f1_score\")\n",
        "  for i in list(pd.DataFrame(np.round(y_val))):\n",
        "    print(f1_score(pd.DataFrame(np.round(pred))[i], pd.DataFrame(np.round(y_val))[i]))\n",
        "\n",
        "  print(\"label_ranking_average_precision_score\")\n",
        "  print(label_ranking_average_precision_score(np.round(pred), y_val))\n",
        "\n",
        "  print(\"hamming_loss\")\n",
        "  print(hamming_loss(np.round(pred), y_val))\n",
        "\n",
        "  model.save(c+'_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}